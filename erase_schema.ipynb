{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ecfe015-32a3-40cd-9768-4442d44fc328",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Erase Schema\n",
    "This notebook drops all user-defined functions, tables, and views from a schema and then removes the schema. Provide the catalog and schema names with the widgets below and run all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b606342b-04c2-45a8-8900-23522a4f671e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    dbutils.widgets.text(\"1.catalog\", \"catalog\")\n",
    "    dbutils.widgets.text(\"2.schema\", \"schema\")\n",
    "    catalog = dbutils.widgets.get(\"1.catalog\")\n",
    "    schema = dbutils.widgets.get(\"2.schema\")\n",
    "except NameError:\n",
    "    catalog = \"do_not_use\"\n",
    "    schema = \"do_not_use\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86d168f6-6cc9-439e-a55c-1b040418338d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"USE CATALOG `{catalog}`;\")\n",
    "print(f\"USE SCHEMA `{schema}`;\")\n",
    "\n",
    "# Drop functions sequentially\n",
    "funcs_df = spark.sql(f\"SHOW USER FUNCTIONS IN `{catalog}`.`{schema}`\")\n",
    "for f in funcs_df.collect():\n",
    "    func_name = f[0]\n",
    "    print(f\"DROP FUNCTION IF EXISTS `{catalog}`.`{schema}`.`{func_name}`;\")\n",
    "\n",
    "# Drop tables sequentially\n",
    "tables_df = spark.sql(f\"SHOW TABLES IN `{catalog}`.`{schema}`\")\n",
    "for t in tables_df.collect():\n",
    "    desc = spark.sql(f\"DESCRIBE EXTENDED `{catalog}`.`{schema}`.`{t.tableName}`\").collect()\n",
    "    t_type = next((row.data_type for row in desc if str(row.col_name).upper() == 'TYPE'), '').upper().replace('_', ' ')\n",
    "    if t_type == 'VIEW':\n",
    "        print(f\"DROP VIEW IF EXISTS `{catalog}`.`{schema}`.`{t.tableName}`;\")\n",
    "    elif t_type == 'MATERIALIZED_VIEW':\n",
    "        print(f\"DROP MATERIALIZED VIEW IF EXISTS `{catalog}`.`{schema}`.`{t.tableName}`;\")\n",
    "    else:\n",
    "        print(f\"DROP TABLE IF EXISTS `{catalog}`.`{schema}`.`{t.tableName}`;\")\n",
    "\n",
    "# Drop external volumes\n",
    "vol_query = f\"\"\"SELECT volume_name FROM system.information_schema.volumes\\nWHERE volume_catalog = '{catalog}' AND volume_schema = '{schema}' AND volume_type = 'EXTERNAL'\"\"\"\n",
    "vol_df = spark.sql(vol_query)\n",
    "for row in vol_df.collect():\n",
    "    print(f\"DROP VOLUME IF EXISTS `{catalog}`.`{schema}`.`{row.volume_name}`;\")\n",
    "\n",
    "print(f\"DROP SCHEMA IF EXISTS `{catalog}`.`{schema}`;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24d16590-e7c8-414a-9409-554c2e3a6cef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Schema `{schema}` in catalog `{catalog}` cleanup complete.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "erase_schema",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}